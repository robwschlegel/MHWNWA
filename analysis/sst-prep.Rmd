---
title: "MHW detection"
author: "Robert Schlegel"
date: "2019-08-22"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
csl: FMars.csl
bibliography: MHWNWA.bib
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(fig.width = 8, fig.align = 'center',
                      echo = TRUE, warning = FALSE, message = FALSE, 
                      eval = TRUE, tidy = FALSE)
```

## Introduction

Building on the work performed in the [study area](https://robwschlegel.github.io/MHWNWA/polygon-prep.html) vignette, we will now create grouped SST time series for the six regions in our study area. We do this by finding which NOAA OISST pixels fall within each of the region polygons. Also note that throughout this vignette (and this entire project) we will use the climatology period of 1993 -- 2018 due to limitations from the data products used for the various [heat budget variables](https://robwschlegel.github.io/MHWNWA/var-prep.html) needed for the [SOM](https://robwschlegel.github.io/MHWNWA/som.html).

```{r libraries}

# Necessary when being run on a server without write privliges
.libPaths(c("~/R-packages", .libPaths()))

# Packages used in this vignette
library(tidyverse) # Base suite of functions
library(heatwaveR) # For detecting MHWs
# cat(paste0("heatwaveR version = ", packageDescription("heatwaveR")$Version))
library(FNN) # For fastest nearest neighbour searches
library(tidync) # For a more tidy approach to managing NetCDF data
library(SDMTools) # For finding points within polygons
library(lubridate) # For convenient date manipulation

# Set number of cores
doParallel::registerDoParallel(cores = 50)

# Disable scientific notation for numeric values
  # I just find it annoying
options(scipen = 999)

# Corners of the study area
NWA_corners <- readRDS("data/NWA_corners.Rda")

# Individual regions
NWA_coords <- readRDS("data/NWA_coords.Rda")

# The base map
map_base <- readRDS("data/map_base.Rda")
```

## Pixel prep

Up first we take the lon/lat grid from the 1/4 degree daily NOAA OISST product and find which points fall within each region. We will save this information to allow us to then easily pull out the desired pixels from the cube of OISST data.

```{r pixel-regions}
# Create the OISST lon/lat grid
OISST_grid <- data.frame(expand.grid(c(seq(0.125, 179.875, by = 0.25), 
                                       seq(-179.875, -0.125, by = 0.25)),
                                     seq(-89.875, 89.875, by = 0.25)))
colnames(OISST_grid) <- c("lon", "lat")

# Trim down OISST grid for faster processing
OISST_grid_region <- OISST_grid %>% 
  filter(lon >= min(NWA_coords$lon),
         lon <= max(NWA_coords$lon),
         lat >= min(NWA_coords$lat),
         lat <= max(NWA_coords$lat))

# Function for finding and cleaning up points within a given region polygon
pnts_in_region <- function(region_in){
  region_sub <- NWA_coords %>% 
    filter(region == region_in)
  coords_in <- pnt.in.poly(pnts = OISST_grid_region[1:2], poly.pnts = region_sub[2:3]) %>% 
    filter(pip == 1) %>% 
    dplyr::select(-pip) %>% 
    mutate(region = region_in)
  return(coords_in)
}

# Run the function
NWA_info <- plyr::ldply(unique(NWA_coords$region), pnts_in_region)
# saveRDS(NWA_info, "data/NWA_info.Rda")

# Visualise to ensure success
ggplot(NWA_coords, aes(x = lon, y = lat)) +
  geom_polygon(aes(fill = region), alpha = 0.2) +
  geom_point(data = NWA_info, aes(colour = region)) +
  geom_polygon(data = map_base, aes(group = group), show.legend = F) +
    coord_cartesian(xlim = NWA_corners[1:2],
                  ylim = NWA_corners[3:4]) +
  labs(x = NULL, y = NULL)
```

## SST prep

With the OISST pixels successfully assigned to regions based on their thermal properties we now average the SST data per pixel into one mean time series per region.

```{r sst-clump, eval=FALSE}
# The OISST data location
OISST_files <- dir("../../data/OISST", full.names = T)

# The files with data in the study area
OISST_files_sub <- data.frame(files = OISST_files,
                              lon = c(seq(0.125, 179.875, by = 0.25), 
                                      seq(-179.875, -0.125, by = 0.25))) %>% 
  filter(lon >= min(NWA_info$lon), lon <= max(NWA_info$lon)) %>% 
  mutate(files = as.character(files))

# Function for loading the individual OISST NetCDF files and subsetting SST accordingly
load_OISST_sub <- function(file_name, coords = NWA_info){
  res <- tidync(file_name) %>%
    hyper_filter(lat = dplyr::between(lat, min(coords$lat), max(coords$lat)),
                 time = dplyr::between(time, as.integer(as.Date("1993-01-01")),
                                       as.integer(as.Date("2018-12-31")))) %>%
    hyper_tibble() %>% 
    mutate(time = as.Date(time, origin = "1970-01-01")) %>% 
    dplyr::rename(temp = sst, t = time) %>% 
    select(lon, lat, t, temp) %>% 
    left_join(coords, by = c("lon", "lat")) %>% 
    filter(!is.na(region))
  return(res)
}

# Put it all together
system.time(
  OISST_region <- plyr::ldply(OISST_files_sub$files,
                              .fun = load_OISST_sub,
                              .parallel = TRUE) %>% 
    group_by(region, t) %>% 
    summarise(temp = mean(temp, na.rm = T)) %>% 
    ungroup()
) # 18 seconds

# Save
# saveRDS(OISST_region, "data/OISST_region.Rda")
```

## MHW detection

With our clumped SST time series ready the last step in this vignette is to detect the MHWs within each.

```{r MHW-sub, eval=FALSE}
# Load the time series data
OISST_region <- readRDS("data/OISST_region.Rda")

# Calculate MHWs
system.time(
  OISST_region_MHW <- OISST_region %>%
    group_by(region) %>%
    nest() %>%
    mutate(clims = map(data, ts2clm,
                       climatologyPeriod = c("1993-01-01", "2018-12-31")),
           events = map(clims, detect_event),
           cats = map(events, category, S = FALSE)) %>%
    select(-data, -clims)
) # 2 seconds
# saveRDS(OISST_region_MHW, "data/OISST_region_MHW.Rda")
```

With the MHWs detected, let's visualise the results to ensure everything worked as expected.

```{r MHW-vis}
# Load MHW results
OISST_region_MHW <- readRDS("data/OISST_region_MHW.Rda")

# Events
OISST_MHW_event <- OISST_region_MHW %>%
  select(-cats) %>%
  unnest(events) %>%
  filter(row_number() %% 2 == 0) %>%
  unnest(events)

MHW_lolli_plot <- ggplot(data = OISST_MHW_event , aes(x = date_peak, y = intensity_cumulative)) + 
        geom_lolli(colour = "salmon", colour_n = "red", n = 0) + 
  labs(x = "Peak Date", y = "Cum. Intensity (Â°C x days)") +
  scale_y_continuous(limits = c(0, 250), expand = c(0,0)) +
  facet_wrap(~region, ncol = 2)
# ggsave(plot = MHW_lolli_plot, filename = "output/MHW_lolli_plot.pdf", height = 6, width = 5)
# ggsave(plot = MHW_lolli_plot, filename = "output/MHW_lolli_plot.png", height = 6, width = 5)

# Visualise
MHW_lolli_plot
```

The lolliplot above shows us that the occurrence of MHWs differs visually between the regions, which is good. A striking early result from this figure is that the distribution of the occurrence of MHWs is left skewed. This means that most of the MHWs are happening later on in the time series. In fact, there are _no_ MHWs detected in the first year of the time series (1993), and only four MHWs detected in the second year (1994) across all regions combined. We don't start to see regular annual occurrence of MHWs until ~1999. This is a classic climate change signal. But it is important to note again that we are using a climatology period of 1993 -- 2018 due to data limitations. This will have the effect of raising the mean climate signal up more than the established WMO period of 1981 -- 2010. The practical effect of this is that we will have an even more pronounced skewness of extreme events towards the end of the time series and the overall intensities of events will be slightly lower.

Finally for this section we will visualise the regions from the previous vignette alongside the lolliplot created here.

```{r MHW-regions-lolli}
# Note that the package cowplot is used below but not loaded explicitly
# This is because it changes the default plotting nature in ways I don't like

# The study area map from the revious vignette
load("output/NWA_study_area.Rdata")

# Merge the panels together
MHW_region_lolli <- cowplot::plot_grid(NWA_study_area, MHW_lolli_plot, labels = c('A)', 'B)'), label_size = 10,
                                       align = 'hv', rel_widths = c(1.2, 1), nrow = 1, axis = "l")
# ggsave(plot = MHW_region_lolli, filename = "output/MHW_region_lolli.pdf", height = 4, width = 10)
# ggsave(plot = MHW_region_lolli, filename = "output/MHW_region_lolli.png", height = 4, width = 10)
MHW_region_lolli
```

```{r MHW_region_lolli_poster, eval=FALSE, echo=FALSE}
# This sneaky chunk is for creating the version used in the poster
# Because of the way that posterdown works one needs to pad the top figure a bit so as not to sit right on the margin

# Empty plot
top_row <- ggplot() + theme_void()

# Steek'em
MHW_region_lolli_pad <- cowplot::plot_grid(top_row, MHW_region_lolli, ncol = 1, rel_heights = c(1, 10))
ggsave(plot = MHW_region_lolli_pad, filename = "poster/MHW_region_lolli_pad.png", height = 4.1, width = 9)
```

Up next in the [heat budget variable preparation](https://robwschlegel.github.io/MHWNWA/var-prep.html) vignette we will go through the steps necessary to build the data that will be fed into our self-organising map (SOM) as seen in the [SOM analysis](https://robwschlegel.github.io/MHWNWA/som.html) vignette.

<!-- One last point however is that according to @Richaud2016 the different slopebreaks for the different regions occur at different depths, from 50 m to 400 m depending. They do however note that using a static definition of 200 m for the break does not produce significantly different results. Therefore, for the time being we will maintain the spatial breaks used above. -->

## References
