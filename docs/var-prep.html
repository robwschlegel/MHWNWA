<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Robert Schlegel" />

<meta name="date" content="2019-05-29" />

<title>Variable preparation</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">MHW Northwest Atlantic</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Overview</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Analyses
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="polygon-prep.html">Polygon preparation</a>
    </li>
    <li>
      <a href="sst-prep.html">SST preparation</a>
    </li>
    <li>
      <a href="var-prep.html">Variable preparation</a>
    </li>
    <li>
      <a href="vec-prep.html">Vector preparation</a>
    </li>
    <li>
      <a href="som.html">SOM analysis</a>
    </li>
    <li>
      <a href="figures.html">Figure creation</a>
    </li>
  </ul>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/robwschlegel/MHWNWA">
    <span class="fa fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Variable preparation</h1>
<h4 class="author"><em>Robert Schlegel</em></h4>
<h4 class="date"><em>2019-05-29</em></h4>

</div>


<p><strong>Last updated:</strong> 2019-06-10</p>
<strong>workflowr checks:</strong> <small>(Click a bullet for more information)</small>
<ul>
<li>
<details>
<p><summary> <strong style="color:blue;">✔</strong> <strong>R Markdown file:</strong> up-to-date </summary></p>
<p>Great! Since the R Markdown file has been committed to the Git repository, you know the exact version of the code that produced these results.</p>
</details>
</li>
<li>
<details>
<p><summary> <strong style="color:blue;">✔</strong> <strong>Environment:</strong> empty </summary></p>
<p>Great job! The global environment was empty. Objects defined in the global environment can affect the analysis in your R Markdown file in unknown ways. For reproduciblity it’s best to always run the code in an empty environment.</p>
</details>
</li>
<li>
<details>
<p><summary> <strong style="color:blue;">✔</strong> <strong>Seed:</strong> <code>set.seed(20190513)</code> </summary></p>
<p>The command <code>set.seed(20190513)</code> was run prior to running the code in the R Markdown file. Setting a seed ensures that any results that rely on randomness, e.g. subsampling or permutations, are reproducible.</p>
</details>
</li>
<li>
<details>
<p><summary> <strong style="color:blue;">✔</strong> <strong>Session information:</strong> recorded </summary></p>
<p>Great job! Recording the operating system, R version, and package versions is critical for reproducibility.</p>
</details>
</li>
<li>
<details>
<p><summary> <strong style="color:blue;">✔</strong> <strong>Repository version:</strong> <a href="https://github.com/robwschlegel/MHWNWA/tree/028d3cc02abc1761fd51e624f1bec0ef6ed68dac" target="_blank">028d3cc</a> </summary></p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility. The version displayed above was the version of the Git repository at the time these results were generated. <br><br> Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
<pre><code>
Ignored files:
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/
    Ignored:    data/NAPA_clim_U.Rda
    Ignored:    data/NAPA_clim_V.Rda
    Ignored:    data/NAPA_clim_W.Rda
    Ignored:    data/NAPA_clim_emp_ice.Rda
    Ignored:    data/NAPA_clim_emp_oce.Rda
    Ignored:    data/NAPA_clim_fmmflx.Rda
    Ignored:    data/NAPA_clim_mldkz5.Rda
    Ignored:    data/NAPA_clim_mldr10_1.Rda
    Ignored:    data/NAPA_clim_qemp_oce.Rda
    Ignored:    data/NAPA_clim_qla_oce.Rda
    Ignored:    data/NAPA_clim_qns.Rda
    Ignored:    data/NAPA_clim_qsb_oce.Rda
    Ignored:    data/NAPA_clim_qt.Rda
    Ignored:    data/NAPA_clim_runoffs.Rda
    Ignored:    data/NAPA_clim_ssh.Rda
    Ignored:    data/NAPA_clim_sss.Rda
    Ignored:    data/NAPA_clim_sst.Rda
    Ignored:    data/NAPA_clim_taum.Rda
    Ignored:    data/NAPA_clim_vars.Rda
    Ignored:    data/NAPA_clim_vecs.Rda
    Ignored:    data/node_mean_all_anom.Rda
    Ignored:    data/packet_all_anom.Rda
    Ignored:    data/som_all_anom.Rda
    Ignored:    data/synoptic_states.Rda
    Ignored:    data/synoptic_vec_states.Rda

Untracked files:
    Untracked:  output/som_plot_uoce_anom.pdf
    Untracked:  output/som_plot_voce_anom.pdf

Unstaged changes:
    Modified:   analysis/MHWNWA.bib
    Modified:   analysis/_site.yml
    Modified:   code/workflow.R
    Modified:   output/som_plot_mldr10_1_anom.pdf
    Modified:   output/som_plot_qt_anom.pdf
    Modified:   output/som_plot_sst_anom.pdf
    Modified:   output/som_plot_taum_anom.pdf

</code></pre>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes.
</details>
</li>
</ul>
<details>
<summary> <small><strong>Expand here to see past versions:</strong></small> </summary>
<ul>
<table style="border-collapse:separate; border-spacing:5px;">
<thead>
<tr>
<th style="text-align:left;">
File
</th>
<th style="text-align:left;">
Version
</th>
<th style="text-align:left;">
Author
</th>
<th style="text-align:left;">
Date
</th>
<th style="text-align:left;">
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/robwschlegel/MHWNWA/028d3cc02abc1761fd51e624f1bec0ef6ed68dac/docs/var-prep.html" target="_blank">028d3cc</a>
</td>
<td style="text-align:left;">
robwschlegel
</td>
<td style="text-align:left;">
2019-06-10
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/robwschlegel/MHWNWA/c61a15f695d6d807427b5642f6e657830a527970/docs/var-prep.html" target="_blank">c61a15f</a>
</td>
<td style="text-align:left;">
robwschlegel
</td>
<td style="text-align:left;">
2019-06-06
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/robwschlegel/MHWNWA/blob/49c610573c920e241a16a0ce72d593e1408b1e90/analysis/var-prep.Rmd" target="_blank">49c6105</a>
</td>
<td style="text-align:left;">
robwschlegel
</td>
<td style="text-align:left;">
2019-06-06
</td>
<td style="text-align:left;">
Finished vector data packet pipeline
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/robwschlegel/MHWNWA/blob/44ac335c253cdc971d10cb55aa0d82ec27f52540/analysis/var-prep.Rmd" target="_blank">44ac335</a>
</td>
<td style="text-align:left;">
robwschlegel
</td>
<td style="text-align:left;">
2019-06-06
</td>
<td style="text-align:left;">
Working on inclusion of vectors into SOM pipeline
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/robwschlegel/MHWNWA/6dd6da87ca5aa18617a30851b7f9cffe25ed7b10/docs/var-prep.html" target="_blank">6dd6da8</a>
</td>
<td style="text-align:left;">
robwschlegel
</td>
<td style="text-align:left;">
2019-06-06
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/robwschlegel/MHWNWA/blob/990693ab94b031163055c994db1364d56ac45c8d/analysis/var-prep.Rmd" target="_blank">990693a</a>
</td>
<td style="text-align:left;">
robwschlegel
</td>
<td style="text-align:left;">
2019-06-05
</td>
<td style="text-align:left;">
First SOM result visuals
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/robwschlegel/MHWNWA/blob/4838cc84c49dfd8bba7cc72cf5131cb56e9345b4/analysis/var-prep.Rmd" target="_blank">4838cc8</a>
</td>
<td style="text-align:left;">
robwschlegel
</td>
<td style="text-align:left;">
2019-06-04
</td>
<td style="text-align:left;">
Working on SOM functions
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/robwschlegel/MHWNWA/blob/94ce8f67d95d2a30c7b904784e619457ee4907a7/analysis/var-prep.Rmd" target="_blank">94ce8f6</a>
</td>
<td style="text-align:left;">
robwschlegel
</td>
<td style="text-align:left;">
2019-06-04
</td>
<td style="text-align:left;">
Functions for creating data packets are up and running
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/robwschlegel/MHWNWA/blob/65301edfa1c7e85df9bf0df7afc2bda432aef6b0/analysis/var-prep.Rmd" target="_blank">65301ed</a>
</td>
<td style="text-align:left;">
robwschlegel
</td>
<td style="text-align:left;">
2019-05-30
</td>
<td style="text-align:left;">
Push before getting rid of some testing structure
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/robwschlegel/MHWNWA/blob/0717c84f720c4b0a65959f2644d54102e7a9a320/analysis/var-prep.Rmd" target="_blank">0717c84</a>
</td>
<td style="text-align:left;">
robwschlegel
</td>
<td style="text-align:left;">
2019-05-29
</td>
<td style="text-align:left;">
Working towards getting the variable climatologies in order
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/robwschlegel/MHWNWA/blob/2c3f68c3bc971b684bc9f3dc03d707457de74f18/analysis/var-prep.Rmd" target="_blank">2c3f68c</a>
</td>
<td style="text-align:left;">
robwschlegel
</td>
<td style="text-align:left;">
2019-05-28
</td>
<td style="text-align:left;">
Working on the variable prep vignette
</td>
</tr>
<tr>
<td style="text-align:left;">
html
</td>
<td style="text-align:left;">
<a href="https://cdn.rawgit.com/robwschlegel/MHWNWA/c09b4f7548427da023cfaf19ba517cb49e9456df/docs/var-prep.html" target="_blank">c09b4f7</a>
</td>
<td style="text-align:left;">
robwschlegel
</td>
<td style="text-align:left;">
2019-05-24
</td>
<td style="text-align:left;">
Build site.
</td>
</tr>
<tr>
<td style="text-align:left;">
Rmd
</td>
<td style="text-align:left;">
<a href="https://github.com/robwschlegel/MHWNWA/blob/5dc8bd9ce2b868ebaefcc3ff83f0289672d22430/analysis/var-prep.Rmd" target="_blank">5dc8bd9</a>
</td>
<td style="text-align:left;">
robwschlegel
</td>
<td style="text-align:left;">
2019-05-24
</td>
<td style="text-align:left;">
Finished initial creation of SST prep vignette.
</td>
</tr>
</tbody>
</table>
</ul>
</details>
<hr />
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>This vignette will walk through the steps needed to create mean ‘whatever’ states during all of the MHWs detected in the previous <a href="https://robwschlegel.github.io/MHWNWA/sst-prep.html">SST preparation</a> vignette. These ‘whatever’ states are any of the abiotic variables present in the NAPA model that have been deemed relevant w.r.t. forcing of extreme ocean surface temperatures.</p>
<pre class="r"><code># Packages used in this vignette
library(jsonlite, lib.loc = &quot;../R-packages/&quot;)
library(tidyverse) # Base suite of functions
library(ncdf4) # For opening and working with NetCDF files
library(lubridate) # For convenient date manipulation

# Load functions required below
source(&quot;code/functions.R&quot;)

# Set number of cores
doMC::registerDoMC(cores = 50)

# Disable scientific notation for numeric values
  # I just find it annoying
options(scipen = 999)

# Corners of the study area
NWA_corners &lt;- readRDS(&quot;data/NWA_corners.Rda&quot;)

# The NAPA data location
NAPA_files &lt;- dir(&quot;../../data/NAPA025/1d_grid_T_2D&quot;, full.names = T)

# The NAPA model lon/lat values
NAPA_coords &lt;- readRDS(&quot;data/NAPA_coords.Rda&quot;)

# Load NAPA bathymetry/lon/lat
NAPA_bathy &lt;- readRDS(&quot;data/NAPA_bathy.Rda&quot;)

# Load MHW results
NAPA_MHW_sub &lt;- readRDS(&quot;data/NAPA_MHW_sub.Rda&quot;)

# MHW Events
NAPA_MHW_event &lt;- NAPA_MHW_sub %&gt;%
  select(-clims, -cats) %&gt;%
  unnest(events) %&gt;%
  filter(row_number() %% 2 == 0) %&gt;%
  unnest(events)</code></pre>
<p>For the upcoming variable prep we are also going to want the NAPA coordinates that are within our chosen study area as seen with <code>NWA_corners</code>. We will also create a subsetted bathy coord file, too, so as to have an effective land mask. This will help us to reduce a lot of computational cost as we go along because many of the pixels over land are given 0 values, rather than missing values, which is a strange choice…</p>
<pre class="r"><code># The NAPPA coordinates for the study area only
NAPA_coords_sub &lt;- NAPA_coords %&gt;% 
  filter(lon &gt;= NWA_corners[1], lon &lt;= NWA_corners[2],
           lat &gt;= NWA_corners[3], lat &lt;= NWA_corners[4])
# saveRDS(NAPA_coords_sub, &quot;data/NAPA_coords_sub.Rda&quot;)

# Tha NAPA bathymetry for the study area only
NAPA_bathy_sub &lt;- NAPA_bathy %&gt;% 
  right_join(NAPA_coords_sub, by = c(&quot;lon_index&quot;, &quot;lat_index&quot;, &quot;lon&quot;, &quot;lat&quot;)) %&gt;% 
  na.omit()
# saveRDS(NAPA_bathy_sub, &quot;data/NAPA_bathy_sub.Rda&quot;)</code></pre>
</div>
<div id="chosen-variables" class="section level2">
<h2>Chosen variables</h2>
<p>There are many variables present in the NAPA model, more than we would really need to use for this project. We have therefore chosen to narrow our investigation. Listed below are all of the variables found within a given NAPA surface layer NetCDF file.</p>
<pre class="r"><code># Spreadsheet of variables present in the NetCDF files
NAPA_vars &lt;- ncdump::NetCDF(NAPA_files[1])$variable[1:6]
NAPA_vars</code></pre>
<pre><code># A tibble: 20 x 6
   name         ndims natts prec   units            longname              
   &lt;chr&gt;        &lt;int&gt; &lt;int&gt; &lt;chr&gt;  &lt;chr&gt;            &lt;chr&gt;                 
 1 emp_ice          3    10 float  kg/m2/s          Evap minus Precip ove…
 2 emp_oce          3    10 float  kg/m2/s          Evap minus Precip ove…
 3 fmmflx           3     9 float  kg/m2/s          Water flux due to fre…
 4 mldkz5           3    10 float  m                Turbocline depth (Kz …
 5 mldr10_1         3    10 float  m                Mixed Layer Depth (ds…
 6 nav_lat          2     3 float  degrees_north    Latitude              
 7 nav_lon          2     3 float  degrees_east     Longitude             
 8 qemp_oce         3     9 float  W/m2             Downward Heat Flux fr…
 9 qla_oce          3    10 float  W/m2             Latent Downward Heat …
10 qns              3     9 float  W/m2             non solar Downward He…
11 qsb_oce          3    10 float  W/m2             Sensible Downward Hea…
12 qt               3    10 float  W/m2             Net Downward Heat Flux
13 runoffs          3    10 float  kg/m2/s          Water Flux into Sea W…
14 ssh              3    10 float  m                sea surface height    
15 sss              3    10 float  0.001            Sea Surface Salinity  
16 sst              3    10 float  degree_C         Sea Surface Temperatu…
17 taum             3    10 float  N/m2             wind stress module    
18 time_center…     1     6 double seconds since 1… Time axis             
19 time_center…     2     0 double &quot;&quot;               time_centered_bounds  
20 time_counte…     2     0 double &quot;&quot;               time_counter_bounds   </code></pre>
<p>These variable are not an unruly amount of information and so we will extract and compile most of them when creating the data packets that will be fed into our SOMs later. Many of these variables are likely to have very high auto-correlative relationships in which case we will need to select only the most representative of them. I foresee the multiple heat terms coming to a head with one another, though I can’t yet say from this early vantage point which will be best.</p>
<p>It should go without saying, but we will not be accounting for lon/lat or the three time variables at the end of the above spreadsheet as these are not proper abiotic variables. Also, upon closer examination it was discovered that the heat terms for sensible (<code>qsb_oce</code>) and latent (<code>qla_oce</code>) heat flux into the ocean do not contain any data, so they cannot be used here. Lastly, we only want to use variables that are present in all of the regions. This means that river runoff (<code>runoffs</code>) is not relevant to this work as it’s localised effects will be reflected in changes to <code>sss</code>, which is a variable present in all regions, whereas river runoff is not. We will also exclude evaporation/preciptation over ice (<code>emp_ice</code>) as this variable is only present in the northern regions. That being said, we will keep water flux due t0 freezing/melting ice (<code>fmmflx</code>), even though this variable does not have data in all regions, because we suspect it may play a role in the formation of MHWs. Specifically as they pertain to phenological shifts in ice formation.</p>
<p>Therefore our initial variable list is as follows:</p>
<pre class="r"><code># Remove unwanted variables
NAPA_vars &lt;- ncdump::NetCDF(NAPA_files[1])$variable[c(2:5, 8, 10, 12, 14:17), 1:6]

# Save
# saveRDS(NAPA_vars, &quot;data/NAPA_vars.Rda&quot;)

NAPA_vars</code></pre>
<pre><code># A tibble: 11 x 6
   name     ndims natts prec  units   longname                            
   &lt;chr&gt;    &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;                               
 1 emp_oce      3    10 float kg/m2/s Evap minus Precip over ocean        
 2 fmmflx       3     9 float kg/m2/s Water flux due to freezing/melting  
 3 mldkz5       3    10 float m       Turbocline depth (Kz = 5e-4)        
 4 mldr10_1     3    10 float m       Mixed Layer Depth (dsigma = 0.01 wr…
 5 qemp_oce     3     9 float W/m2    Downward Heat Flux from E-P over op…
 6 qns          3     9 float W/m2    non solar Downward Heat Flux        
 7 qt           3    10 float W/m2    Net Downward Heat Flux              
 8 ssh          3    10 float m       sea surface height                  
 9 sss          3    10 float 0.001   Sea Surface Salinity                
10 sst          3    10 float degree… Sea Surface Temperature             
11 taum         3    10 float N/m2    wind stress module                  </code></pre>
</div>
<div id="synoptic-states" class="section level2">
<h2>Synoptic states</h2>
<p>With the variables chosen, the next step is to create mean synoptic states for each variable during each of the MHWs detected in all sub-regions. In order to make that process go more smoothly we will first create a date index of all of the NAPA files present on Eric Oliver’s local server. Unfortunately that means that from here out the code in this vignette will only run on said server. The output of this vignette will however be publicly available <a href="https://github.com/robwschlegel/MHWNWA/tree/master/data">here</a>.</p>
<div id="date-index-for-napa-files" class="section level3">
<h3>Date index for NAPA files</h3>
<p>To create the index of dates to be found within each of the thousands of NAPA surface NetCDF files we will use a simple for loop to crawl through the files and write down for us in one long spreadsheet which dates are to be found in which files. While this could be done on the fly in the following steps, it will just be easier to have a stable index prepared.</p>
<pre class="r"><code># Pull out the dates
NAPA_files_dates &lt;- data.frame()
for(i in 1:length(NAPA_files)){
  file_name &lt;- NAPA_files[i]
  date_start &lt;- ymd(str_sub(basename(as.character(file_name)), start = 29, end = 36))
  date_end &lt;- ymd(str_sub(basename(as.character(file_name)), start = 38, end = 45))
  date_seq &lt;- seq(date_start, date_end, by = &quot;day&quot;)
  date_info &lt;- data.frame(file = file_name, date = date_seq)
  NAPA_files_dates &lt;- rbind(date_info, NAPA_files_dates)
}

# Order by date, just for tidiness
NAPA_files_dates &lt;- dplyr::arrange(NAPA_files_dates, date)

# Save
# saveRDS(NAPA_files_dates, &quot;data/NAPA_files_dates.Rda&quot;)</code></pre>
</div>
<div id="variable-climatologies" class="section level3">
<h3>Variable climatologies</h3>
<p>Part of the data packet we need to create for the SOMs is the anomaly values. In order to create anomalies however we need to first create climatologies for all of the variables. This may prove to be a somewhat daunting task, but it’s what we are here to do! In order to create a climatology of values we will need to load all of the files and then pixel-wise go about getting the seasonal (daily) climatologies. This will be done with the same function (<code>ts2clm()</code>) that is used for the MHW climatologies. We will first create a function that extracts the desired variables from any NetCDF files fed to it. With that done it should be a routine matter to get the climatologies. Hold onto your hats, this is going to be RAM heavy…</p>
<pre class="r"><code># Load functions required below
source(&quot;code/functions.R&quot;)

# NB: The creation of a clim for one variable is too large to run via ldply
# Rather they must be run one at a time via a for loop and the memmory dumped after each
for(i in 1:nrow(NAPA_vars)){
  clim_one_var(NAPA_vars$name[i])
  gc()
}</code></pre>
<p>With that large hurdle jumped, let’s double down and join all of these data together for ease of loading in the future.</p>
<pre class="r"><code># Load all variable climatologies and join variables with a for loop
  # NB: This should be optimised...
NAPA_clim_vars &lt;- data.frame()
# system.time(
for(i in 1:length(NAPA_vars$name)){
  var_one &lt;- readRDS(file = paste0(&quot;data/NAPA_clim_&quot;,NAPA_vars$name[i],&quot;.Rda&quot;))
  if(nrow(NAPA_clim_vars) == 0){
    NAPA_clim_vars &lt;- rbind(var_one, NAPA_clim_vars)
  } else {
    NAPA_clim_vars &lt;- left_join(NAPA_clim_vars, var_one, 
                                by = c(&quot;lon&quot;, &quot;lat&quot;, &quot;doy&quot;))
  }
}
# ) # 115 seconds for all
rm(var_one, i); gc()

# Convert DOY to MM-DD for joining to daily data below
NAPA_clim_vars$doy &lt;- format(as.Date(NAPA_clim_vars$doy, origin = &quot;2015-12-31&quot;), &quot;%m-%d&quot;)

# Change column names to highlight that these are climatology values
colnames(NAPA_clim_vars)[-c(1:3)] &lt;- paste0(colnames(NAPA_clim_vars)[-c(1:3)],&quot;_clim&quot;)

# Reorder columns
# NAPA_clim_vars &lt;- dplyr::select(NAPA_clim_vars, lon, lat, doy, everything())

# saveRDS(NAPA_clim_vars, &quot;data/NAPA_clim_vars.Rda&quot;)</code></pre>
</div>
<div id="variable-extractor" class="section level3">
<h3>Variable extractor</h3>
<p>We needed a list of the dates present in each file so that we can easily load only the NetCDF files we need to extract our desired variables. The dates we want are the range of dates during each of the MHWs detected in the <a href="https://robwschlegel.github.io/MHWNWA/sst-prep.html">SST preparation</a> vignette. In the chunk below we will create a function that decides which files should have their variables loaded and a function that binds everything up into tidy data packets that our SOM can ingest.</p>
<pre class="r"><code># Load NAPA file date index
NAPA_files_dates &lt;- readRDS(&quot;data/NAPA_files_dates.Rda&quot;)

# Load full variable climatology file
NAPA_clim_vars &lt;- readRDS(&quot;data/NAPA_clim_vars.Rda&quot;)

# Function for extracting the desired variables from a given NetCDF file
# testers...
# file_name &lt;- NAPA_files[1]
extract_all_var &lt;- function(file_name){
  
  # Extract and join variables with a for loop
    # NB: This should be optimised...
  NAPA_vars_extracted &lt;- data.frame()
  system.time(
  for(i in 1:length(NAPA_vars$name)){
    extract_one &lt;- extract_one_var(NAPA_vars$name[i], file_name = file_name)
    if(nrow(NAPA_vars_extracted) == 0){
      NAPA_vars_extracted &lt;- rbind(extract_one, NAPA_vars_extracted)
    } else {
      NAPA_vars_extracted &lt;- left_join(NAPA_vars_extracted, extract_one, 
                                       by = c(&quot;lon_index&quot;, &quot;lat_index&quot;, &quot;lon&quot;, &quot;lat&quot;, &quot;bathy&quot;, &quot;t&quot;))
    }
  }
  ) # 18 seconds for one
  NAPA_vars_extracted &lt;- dplyr::select(NAPA_vars_extracted,
                                       lon_index, lat_index, lon, lat, t, bathy, everything())
  
  # Exit
  return(NAPA_vars_extracted)
}

# Function for extracting variables from as many files as a MHW event requires
# testers...
# event_sub &lt;- NAPA_MHW_event[23,]
data_packet &lt;- function(event_sub){
  
  # Create date and file index for loading
  date_idx &lt;- seq(event_sub$date_start, event_sub$date_end, by = &quot;day&quot;)
  file_idx &lt;- filter(NAPA_files_dates, date %in% date_idx) %&gt;% 
    mutate(file = as.character(file)) %&gt;% 
    select(file) %&gt;% 
    unique()
  
  # Load required base data
  # system.time(
  packet_base &lt;- plyr::ldply(file_idx$file, extract_all_var) %&gt;% 
    filter(t %in% date_idx) %&gt;% 
    mutate(doy = format(t, &quot;%m-%d&quot;))
  # ) # 125 seconds for seven files
  
  # Join to climatologies
  packet_join &lt;- left_join(packet_base, NAPA_clim_vars, by = c(&quot;lon&quot;, &quot;lat&quot;, &quot;doy&quot;))
  
  # Create anomaly values and remove clim columns
  packet_anom &lt;- packet_join %&gt;% 
    mutate(emp_oce_anom = emp_oce - emp_oce_clim,
           fmmflx_anom = fmmflx - fmmflx_clim,
           mldkz5_anom = mldkz5 - mldkz5_clim,
           mldr10_1_anom = mldr10_1 - mldr10_1_clim,
           qemp_oce_anom = qemp_oce - qemp_oce_clim,
           qns_anom = qns - qns_clim,
           qt_anom = qt - qt_clim,
           ssh_anom = ssh - ssh_clim,
           sss_anom = sss - sss_clim,
           sst_anom = sst - sst_clim,
           taum_anom = taum - taum_clim) %&gt;% 
    dplyr::select(lon, lat, doy, emp_oce:taum_anom, 
                  -c(colnames(NAPA_clim_vars)[-c(1:3)]))
    # dplyr::select(-c(colnames(packet_base)[-c(3,4,ncol(packet_base))]), 
    #               -c(colnames(NAPA_clim_vars)[-c(1:3)]))
  
  # Create mean synoptic values
  packet_mean &lt;- packet_anom %&gt;% 
    select(-doy) %&gt;% 
    # NB: The lowest pixels are a forcing edge and shouldn&#39;t be included
      # We can catch these out by filtering pixels whose SST is exactly 0
    filter(sst != 0) %&gt;% 
    group_by(lon, lat) %&gt;% 
    summarise_all(mean, na.rm = T) %&gt;% 
    arrange(lon, lat) %&gt;% 
    ungroup() %&gt;% 
    nest(.key = &quot;synoptic&quot;)
  
  # Combine results with MHW dataframe
  packet_res &lt;- cbind(event_sub, packet_mean)
  
  # Test visuals
  # ggplot(packet_mean, aes(x = lon, y = lat)) +
  #   geom_point(aes(colour = sst_anom)) +
  #   scale_colour_gradient2(low = &quot;blue&quot;, high = &quot;red&quot;) +
  #   coord_cartesian(xlim = NWA_corners[1:2],
  #                   ylim = NWA_corners[3:4])
  
  # Exit
  return(packet_res)
}</code></pre>
<p>With our functions sorted, it is now time to create our data packets.</p>
<pre class="r"><code># Set number of cores
  # NB: Was set to 25 as someone else was using the server at the time
doMC::registerDoMC(cores = 25)

# Create one big packet
# system.time(
synoptic_states &lt;- plyr::ddply(NAPA_MHW_event, c(&quot;region&quot;, &quot;sub_region&quot;, &quot;event_no&quot;), data_packet, .parallel = T)
# ) # 82 seconds for first 2, 6125 seconds (102 minutes) for all

# Save
# saveRDS(synoptic_states, &quot;data/synoptic_states.Rda&quot;)</code></pre>
<p>With all of our synoptic snapshots for our chosen variables created it is now time to feed them to the <a href="https://robwschlegel.github.io/MHWNWA/som.html">Self-organising map (SOM) analysis</a>.</p>
<div id="refs">

</div>
</div>
</div>
<div id="session-information" class="section level2">
<h2>Session information</h2>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.6.0 (2019-04-26)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.5 LTS

Matrix products: default
BLAS:   /usr/lib/openblas-base/libblas.so.3
LAPACK: /usr/lib/libopenblasp-r0.2.18.so

locale:
 [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8    
 [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8   
 [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] bindrcpp_0.2.2       tidync_0.2.1         heatwaveR_0.3.6.9004
 [4] data.table_1.11.6    lubridate_1.7.4      ncdf4_1.16          
 [7] forcats_0.3.0        stringr_1.3.1        dplyr_0.7.6         
[10] purrr_0.2.5          readr_1.1.1          tidyr_0.8.1         
[13] tibble_1.4.2         ggplot2_3.0.0        tidyverse_1.2.1     
[16] jsonlite_1.6        

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.18      lattice_0.20-35   utf8_1.1.4       
 [4] assertthat_0.2.0  rprojroot_1.3-2   digest_0.6.16    
 [7] foreach_1.4.4     R6_2.2.2          cellranger_1.1.0 
[10] plyr_1.8.4        backports_1.1.2   evaluate_0.11    
[13] httr_1.3.1        pillar_1.3.0      rlang_0.2.2      
[16] lazyeval_0.2.1    readxl_1.1.0      ncmeta_0.0.4     
[19] rstudioapi_0.7    whisker_0.3-2     R.utils_2.7.0    
[22] R.oo_1.22.0       rmarkdown_1.10    htmlwidgets_1.3  
[25] munsell_0.5.0     broom_0.5.0       compiler_3.6.0   
[28] modelr_0.1.2      pkgconfig_2.0.2   htmltools_0.3.6  
[31] tidyselect_0.2.4  workflowr_1.1.1   codetools_0.2-15 
[34] doMC_1.3.5        fansi_0.3.0       viridisLite_0.3.0
[37] crayon_1.3.4      withr_2.1.2       R.methodsS3_1.7.1
[40] grid_3.6.0        nlme_3.1-137      gtable_0.2.0     
[43] git2r_0.23.0      magrittr_1.5      scales_1.0.0     
[46] cli_1.0.0         stringi_1.2.4     xml2_1.2.0       
[49] iterators_1.0.10  tools_3.6.0       glue_1.3.0       
[52] RNetCDF_1.9-1     maps_3.3.0        hms_0.4.2        
[55] ncdump_0.0.3      parallel_3.6.0    yaml_2.2.0       
[58] colorspace_1.3-2  rvest_0.3.2       plotly_4.9.0     
[61] knitr_1.20        bindr_0.1.1       haven_1.1.2      </code></pre>
</div>

<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>

<hr>
<p>
  This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a>
  analysis was created with
  <a href="https://github.com/jdblischak/workflowr">workflowr</a> 1.1.1
</p>
<hr>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
